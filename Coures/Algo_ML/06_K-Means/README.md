## ğŸ“Œ **L'algorithme K-Means : Clustering non supervisÃ©**

Lâ€™algorithme **K-Means** est une **mÃ©thode de clustering** qui regroupe des points de donnÃ©es en **K clusters** en minimisant la variance intra-cluster.

---

## ğŸ”¹ **Comment fonctionne K-Means ?**

1ï¸âƒ£ **Initialisation** : On choisit \( K \) centres alÃ©atoires.  
2ï¸âƒ£ **Assignation** : Chaque point est assignÃ© au centre le plus proche (via la distance Euclidienne).  
3ï¸âƒ£ **Mise Ã  jour** : On recalcule les **centres** en prenant la moyenne des points de chaque cluster.  
4ï¸âƒ£ **RÃ©pÃ©tition** : On recommence **jusqu'Ã  convergence** (plus de changements).

ğŸš€ **But :** Minimiser la somme des distances au carrÃ© entre chaque point et son centre.  
\[
J = \sum*{i=1}^{K} \sum*{x \in C_i} || x - \mu_i ||^2
\]
oÃ¹ \( C_i \) est le cluster \( i \) et \( \mu_i \) son centroÃ¯de.

---

## ğŸ“œ **Exemple en Python avec Visualisation**

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs

# GÃ©nÃ©rer des donnÃ©es avec 3 clusters
X, _ = make_blobs(n_samples=300, centers=3, cluster_std=1.0, random_state=42)

# Appliquer K-Means avec K=3
kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
kmeans.fit(X)

# PrÃ©dictions des clusters
labels = kmeans.predict(X)
centroids = kmeans.cluster_centers_

# Affichage des clusters et centroÃ¯des
plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', alpha=0.6)
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label="CentroÃ¯des")
plt.title("Clustering avec K-Means")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()
```

---

## ğŸ”¹ **Explication du Code**

âœ… **`make_blobs()`** : GÃ©nÃ¨re des **donnÃ©es artificielles** avec 3 clusters.  
âœ… **`KMeans(n_clusters=3)`** : Applique lâ€™algorithme avec \( K=3 \).  
âœ… **`kmeans.fit(X)`** : EntraÃ®ne K-Means sur les donnÃ©es.  
âœ… **Visualisation** :

-   **Couleurs = clusters**
-   **Points rouges = centroÃ¯des**

---

## ğŸ“Œ **AmÃ©liorations possibles :**

ğŸ”¹ Trouver le **meilleur K** avec la **mÃ©thode du coude** ğŸ“‰.  
ğŸ”¹ Tester d'autres mÃ©triques de distance (Manhattan, Cosine, etc.).  
ğŸ”¹ Essayer **K-Means++** pour une meilleure initialisation.

Tu veux voir un exemple avec la **mÃ©thode du coude** pour choisir \( K \) ? ğŸš€
