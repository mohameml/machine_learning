{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 1px solid #004ecb; padding: 2em;\">\n",
    "<b style=\"font-size: 20pt;\">TP4: Stochastic gradient & co</b> <br> <br>\n",
    "<b style=\"font-size: 15pt; color: #bbdefb\">Ensimag 2A — Special grading lab</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student: MOhamed Ahmed Mohamed Lemine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Automatic reload of local libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**[0. Context](#0.-Context)**<br>\n",
    "**[I. Introduction](#I.-Introduction)**<br> \n",
    "**[II. The optimization problem](#II.-The-optimization-problem)**<br>\n",
    "**[III. Implementing the solvers](#III.-Implementing-the-solvers)**<br>\n",
    "&nbsp; &nbsp; &nbsp;[GD (Gradient descent)](#GD-(Gradient-descent))<br>\n",
    "&nbsp; &nbsp; &nbsp;[SGD (Stochastic Gradient Descent)](#SGD-(Stochastic-Gradient-Descent)<br>\n",
    "&nbsp; &nbsp; &nbsp;[SAGA (Stochastic Average Gradient \"Amélioré\")](#SAGA-(Stochastic-Average-Gradient-\"Amélioré\")<br>\n",
    "&nbsp; &nbsp; &nbsp;[Comparison](#Comparison)<br>\n",
    "**[IV. Regularization](#IV.-Regularization)**<br>\n",
    "**[V. Further development](#V.-Further-development)**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you will implement optimization algorithms that we've studied together and use them to fit a logistic regression classification model. Parts of this lab intersect TP2 and 3.\n",
    "\n",
    "You will be implementing a simplified version of [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). \n",
    "\n",
    "Part of the work has already been done for you (see the `./lib` folder), so you'll only have to implement the `##### TODO (i) #####` sections of the code. \n",
    "\n",
    "Report in groups of 1 to 2 students (1 student advised). <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>0. Context</h1>\n",
    "</div>\n",
    "\n",
    "As in the last session, we shall study the logistic regression of a data matrix to binary-encoded labels (see the introduction section).\n",
    "This time, to avoid to compute costly gradients, one may try to consider the data points (the rows of $A$) as random variables sampled via an uniform distribution. They may then consider a minimization proflem of a loss $L: x\\to L(x)$, in which the loss is not deterministic anymore, it corresponds to the average loss with respect to the random data points $a$ of \"per-sample losses\" $F$:\n",
    "$$\n",
    "L(x) := \\mathbb{E}_{a\\sim\\mathbb{P}}[F(a;x)]\n",
    "$$\n",
    "\n",
    "Since the true distribution generating the randomness of $a$ is not known in most cases, one may approximate the above expression with the data points of the design matrix $A$, sampled from its rows ($\\forall i\\le n$: $a_i:=(A)_{i, :}$) randomly:\n",
    "$$\n",
    "L(x) \\approx \\underbrace{\\mathbb{E}_{i\\sim\\mathcal{U}(0, n)}[F(a_i;x)]}_{=:L_n(x)}\n",
    "$$\n",
    "Minimizing this functional is called the empirical risk minimization.\n",
    "\n",
    "One very good and useful property is that the gradient of this estimator is, at least, unbiased for the empirical distribution:\n",
    "$$\n",
    "\\underbrace{\\nabla_x L(x) = \\mathbb{E}_{a\\sim\\mathbb{P}}[\\nabla_x F(a;x)]}_{\\text{\"true\" gradient(s)}} \\approx \\underbrace{\\nabla_x L_n(x) = \\nabla_x \\left(\\mathbb{E}_{i\\sim\\mathcal{U}(0, n)}[F(a_i;x)]\\right) = \\mathbb{E}_{i\\sim\\mathcal{U}(0, n)}[\\nabla_x F(a_i;x)]}_{\\text{estimation}}\n",
    "$$\n",
    "\n",
    "So the main idea of this last session is to implement an algorithm performing gradient steps only in the \"per sample\" loss.\n",
    "\n",
    "You will implement three algorithms, and send your reports by email in a zip format containing the filled files and the notebook, with **as much comments on your attempts as you can write**.\n",
    "\n",
    "You must discuss your choices, and write good readable code. The goal is to compare the three methods with valid implementations:\n",
    "\n",
    "* the first one is the vanilla Gradient Descent, taking the average of the gradients at each step\n",
    "* second is the stochastic gradient, taking at each step a random sample\n",
    "* third is the saga algorithm, which improves on sgd by relying on a memory of some past gradients. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>I. Introduction</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in previous labs, we consider the [Student Performance](http://archive.ics.uci.edu/ml/datasets/Student+Performance) dataset. This dataset contains student demographic, social, school-related features, how many classes they've missed, etc. \n",
    "\n",
    "The goal we give ourselves is to predict whether a student will pass (final grade > 12).\n",
    "\n",
    "We denote $A \\in \\mathcal{M}_{n,d}(\\mathbb{R})$ the feature matrix, containing $n$ samples with $d$ features, and $b \\in \\{-1,1\\}^n$ the label vector where $-1$ encodes `fail` and $1$ encodes `pass`.\n",
    "\n",
    "The data has already been preprocessed: You can check ```lib/datasets.py``` if you're curious. The following loads the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lib.datasets import load_student_data\n",
    "\n",
    "A_train, A_test, b_train, b_test = load_student_data('data/student-mat.csv', split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, you're going to implement a simplified version of [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). So let's first see the type of output it is supposed to give. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe; border-left: 5px solid #2962ff; padding: 0.5em;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  \n",
    "    <ul style=\"color: black\">\n",
    "        <li> Import the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\">sklearn.linear_model.LogisticRegression </a> class. </li>\n",
    "        <li> Create an instance of sklearn's logistic regression classifiers with SAGA as its solver. (You may decrease the target accuracy to 0.001) </li>\n",
    "        <li> Fit the classifier on the training data and compute the score of the fitted model on the test set.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(tol=0.001, solver=\"saga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;saga&#x27;, tol=0.001)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(solver=&#x27;saga&#x27;, tol=0.001)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(solver='saga', tol=0.001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8787878787878788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(A_test, b_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>II. The optimization problem</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression consists in finding the parameter $x \\in \\mathbb{R}^d$ that best fits:\n",
    "$$\n",
    "b_i = \\begin{cases}\n",
    "\\phantom{-}1 \\ \\textrm{ if }\\ \\langle a_{i}, x\\rangle \\ge 0 \\\\\n",
    "-1 \\ \\textrm{ if }\\ \\langle a_{i}, x\\rangle < 0 \n",
    "\\end{cases}\n",
    "$$\n",
    "for all the samples $i$ of the training set (where $a_i$ is the $i^{th}$ line of $A$ and $b_i$ the $i^{th}$ element of $b$). To measure this fit, logistic regression chooses the following loss:\n",
    "\n",
    "$$\n",
    "\\textrm{LogisticLoss}(b_i, \\left\\langle a_{i}, x\\right\\rangle ) = \\log \\left(1+\\exp \\left(-b_{i}\\left\\langle a_{i}, x\\right\\rangle\\right)\\right) \n",
    "$$\n",
    "\n",
    "The corresponding optimization problem we will consider is the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #eceff1; border-left: 0px solid #78909c; padding: 2em; border-radius: 5px; color: black\"> \n",
    "\n",
    "Minimization of the empirical risk $f$ of the $L_2$-regularized logistic regression model, on the dataset $(A_{\\textrm{train}},b_{\\textrm{train}})$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\textrm{min}_{x\\in \\mathbb{R}^d} \\  f(x) \n",
    "\\ &= \\ \\textrm{min}_{x\\in \\mathbb{R}^d} \\ \\frac{1}{n_{\\textrm{train}}} \\sum_{i=1}^{n_{\\textrm{train}}} f_i(x) \\\\\n",
    "&= \\ \\textrm{min}_{x\\in \\mathbb{R}^d}\\frac{1}{n_{\\textrm{train}}} \\sum_{i=1}^{n_{\\textrm{train}}} \\textrm{LogisticLoss}(b_i, \\left\\langle a_{i}, x\\right\\rangle ) + \\frac{l_2}{2}\\|x\\|^{2}_2,  \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $l_2 \\ge 0$ is the regularization parameter.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the notation, we'll stop indexing $A$, $b$ and $n$ with \"$\\textrm{train}$\" in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the functions $f_i$s and $f$ are $C^1$ with $L$-Lischitz gradient, with $L \\le \\frac{\\max_i\\|a_i\\|^2_2}{4} + l_2$ and we can therefore use the following value in our implementation:\n",
    "```python\n",
    "L = 0.25 * max(np.linalg.norm(A,2,axis=1))**2 + self.l2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>III. Implementing the solvers</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement gradient methods, we need an oracle that will compute both batch gradients $\\nabla f$ and partial gradients $\\nabla f_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em;color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  In the code below, $\\nabla f$ has already been implemented.\n",
    "    <ul style=\"color: black\">\n",
    "        <li> Complete <b>TODO (1)</b> in <code>lib/linear_model.py</code>.</li>\n",
    "        <li> Add your code to <code>lib/linear_model.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em;color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  The solvers backbones have been implemented, study them before filling the code for the little parts.\n",
    "    <ul style=\"color: black\">\n",
    "        <li> Read carefuly <code>lib/solvers.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD (Gradient descent) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At iteration k of the GD algorithm, the following update is executed:\n",
    "\n",
    "$$\n",
    "x_{k+1} \\leftarrow x_{k} - \\gamma\\nabla f(x_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  \n",
    "    <ul>\n",
    "        <li> What stepsize $\\gamma$ ensures the convergence of this algorithm ?</li>\n",
    "        <li> Complete <b>TODO (2)</b> with the correct step size and <b>TODO (3)</b> with the gradient step</li>\n",
    "        <li> Add your code to <code>lib/gd.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color:black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> Run the code below to test your code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "TODO (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisuals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m learning_curve\n\u001b[1;32m      4\u001b[0m clf_gd \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgd\u001b[39m\u001b[38;5;124m'\u001b[39m, l2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mclf_gd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m learning_curve(GD\u001b[38;5;241m=\u001b[39mclf_gd)\n",
      "File \u001b[0;32m~/github/02_Info/07_intelligence_artificielle/01_machine_learning/Exercices/04_descente_stochastique/lib/linear_model.py:76\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, A, b)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad(x, A, b, i)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Last iterate of the optimization, and table of all the iterates\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coef_tab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# start point\u001b[39;49;00m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_grad_for_Ab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# gradient closure\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# prox operator closure\u001b[39;49;00m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# max number of iterations\u001b[39;49;00m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# number of students in the dataset\u001b[39;49;00m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Lips constant of the gradient of the smooth part of the loss\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# strong convexity constant of the loss\u001b[39;49;00m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_empirical_risk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28msum\u001b[39m([\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logistic_loss(A, b, x)) \u001b[38;5;241m/\u001b[39m n,\n\u001b[1;32m     88\u001b[0m     reg_l2(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml2),\n\u001b[1;32m     89\u001b[0m     reg_l1(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1)\n\u001b[1;32m     90\u001b[0m ])\n",
      "File \u001b[0;32m~/github/02_Info/07_intelligence_artificielle/01_machine_learning/Exercices/04_descente_stochastique/lib/solvers.py:50\u001b[0m, in \u001b[0;36mGD\u001b[0;34m(x0, grad, prox, max_iter, n, L, mu)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    table of all the iterates\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Initialize an array (buffer) containing pas gradients\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# computed wrt one data point\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m stepsize_0 \u001b[38;5;241m=\u001b[39m \u001b[43mgd_stepsize_start\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m x \u001b[38;5;241m=\u001b[39m x0\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# x_tab contains all the iterates.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# It is returned in a (v)stacked format\u001b[39;00m\n",
      "File \u001b[0;32m~/github/02_Info/07_intelligence_artificielle/01_machine_learning/Exercices/04_descente_stochastique/lib/gd.py:27\u001b[0m, in \u001b[0;36mgd_stepsize_start\u001b[0;34m(n, mu, L)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03mA function to choose the starting step-size of the algorithm, i.e. its step-size for the first iteration.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    (Approximate ?) Lipschitz constant of the gradient of the objective.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ####### TODO (2) ########\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTODO (2)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: TODO (2)"
     ]
    }
   ],
   "source": [
    "from lib.linear_model import LogisticRegression\n",
    "from lib.visuals import learning_curve\n",
    "\n",
    "clf_gd = LogisticRegression(solver='gd', l2=0.01, max_iter=100)\n",
    "clf_gd.fit(A_train, b_train)\n",
    "\n",
    "learning_curve(GD=clf_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At iteration k of the SGD algorithm, the following update is executed:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "i \\textrm{ chosen randomly in } \\{1...n\\}\\\\\n",
    "x_{k+1} \\leftarrow x_{k} - \\gamma_k \\nabla f_i(x_k) \\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  \n",
    "    <ul>\n",
    "        <li> What stepsize $\\gamma_k$ ensures the convergence of this algorithm and under what assumptions? Provide your own line of reasonning, be it by relying on litterature or by trying multiple combinations.</li>\n",
    "        <li> Complete <b>TODO (4)</b> (both the stepsize functions and the stepping function)</li>\n",
    "        <li> Add your code to <code>lib/sgd.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> Run the code below to test your code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_sgd = LogisticRegression(solver='sgd', l2=0.01, max_iter=100*len(b_train))\n",
    "clf_sgd.fit(A_train, b_train)\n",
    "\n",
    "learning_curve(SGD=clf_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAGA (Stochastic Average Gradient \"Amélioré\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAGA starts by computing a single batch gradient, then at iteration k, the following update is executed:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "i \\textrm{ chosen randomly in } \\{1...n\\}\\\\\n",
    "x_{k+1} \\leftarrow x_{k} - \\gamma_k\\big(\\nabla f_i(x_k) - \\alpha_i + \\bar{\\alpha}\\big) \\\\\n",
    "\\alpha_i \\leftarrow \\nabla f_i(x) \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $(\\alpha_j)_{j=1}^n$ are gradients evaluated at previous iterates and $\\bar{\\alpha}=\\frac{1}{n}\\sum^n_{j=1}\\alpha_j$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b>  \n",
    "    <ul>\n",
    "        <li> What stepsize $\\gamma_k$ ensures the convergence of this algorithm and under what assumptions (propose ideas, no demonstration needed)?</li>\n",
    "        <li> Complete <b>TODO (5)</b></li>\n",
    "        <li> Add your code to <code>lib/saga.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> Run the code below to test your code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_saga = LogisticRegression(solver='saga', l2=0.01, max_iter=30*len(b_train))\n",
    "clf_saga.fit(A_train, b_train)\n",
    "\n",
    "learning_curve(SAGA=clf_saga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> Run the code below to compare all the methods you've implemented.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "n = len(b_train)\n",
    "\n",
    "clf_gd   = LogisticRegression(solver='gd', l2=0.01, max_iter=epochs)\n",
    "clf_sgd  = LogisticRegression(solver='sgd', l2=0.01, max_iter=epochs*n)\n",
    "clf_saga = LogisticRegression(solver='saga', l2=0.01, max_iter=epochs*n)\n",
    "\n",
    "clf_gd.fit(A_train, b_train)\n",
    "clf_sgd.fit(A_train, b_train)\n",
    "clf_saga.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(GD=clf_gd, SGD=clf_sgd, SAGA=clf_saga)\n",
    "\n",
    "for clf, name in zip([clf_gd, clf_sgd, clf_saga], ['gd', 'sgd', 'saga']):\n",
    "    print(name + ':' \\\n",
    "          + \"\\tAccuracy on training set: {0:0.1f}%\".format(100*clf.score(A_train, b_train)))\n",
    "    print(\"\\tAccuracy on testing set:  {0:0.1f}%\".format(100*clf.score(A_test, b_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>IV. Regularization</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> \n",
    "    <ul>\n",
    "        <li> Rewrite the empirical risk minimization objective with both $L_1$ and $L_2$ regularization (with coefficients $l_1$ and $l_2$).</li>\n",
    "        <li> Is this objective $\\mu$-strongly convex, $L$-smooth, differentiable?</i>\n",
    "        <li> Complete the <b>TODO (6)</b> to account for the new term in the objective.</i>\n",
    "        <li> Add your code to <code>lib/regularize.py</code>.</i>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimization algorithms we've implemented have a slow rate of convergence for this new objective function. We will therefore use *proximal* variations of these algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> Using the $\\textrm{prox}_{l_1 \\|\\cdot\\|_1}$ operator, write down the $k^{th}$ step of proximal GD, proximal SGD, and proximal SAGA.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to what we did on the last session:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> \n",
    "    <ul>\n",
    "        <li> Give a closed-form expression of $\\textrm{prox}_{l_1 \\|\\cdot\\|_1}$</li>\n",
    "        <li> Complete <b>TODO (7)</b> (note that you can access the $l_1$ coefficient using <b>self.l1</b>).</li>\n",
    "        <li> Add your code to <code>lib/linear_model.py</code>.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "n = len(b_train)\n",
    "\n",
    "clf_gd   = LogisticRegression(solver='gd', l2=0.01, l1=0.01, max_iter=epochs)\n",
    "clf_sgd  = LogisticRegression(solver='sgd', l2=0.01, l1=0.01, max_iter=epochs*n)\n",
    "clf_saga = LogisticRegression(solver='saga', l2=0.01, l1=0.01, max_iter=epochs*n)\n",
    "\n",
    "clf_gd.fit(A_train, b_train)\n",
    "clf_sgd.fit(A_train, b_train)\n",
    "clf_saga.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve(GD=clf_gd, SGD=clf_sgd, SAGA=clf_saga)\n",
    "\n",
    "for clf, name in zip([clf_gd, clf_sgd, clf_saga], ['gd', 'sgd', 'saga']):\n",
    "    print(name + ':' \\\n",
    "          + \"\\tAccuracy on training set: {0:0.1f}%\".format(100*clf.score(A_train, b_train)))\n",
    "    print(\"\\tAccuracy on testing set:  {0:0.1f}%\".format(100*clf.score(A_test, b_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> If your proximal gradient is correctly implemented, the following cell plots the support of the solution for various values of $l_1$.\n",
    "    <ul>\n",
    "        <li> Interpret the plot and explain what can $L_1$ regularization be used for.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.visuals import l1_regularization_plot\n",
    "\n",
    "clf = lambda l1: LogisticRegression(solver='gd', l1=l1, l2=0.1, max_iter=1000)\n",
    "\n",
    "l1_regularization_plot(clf, A_train, b_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #e1f5fe;  border-left: 5px solid #2962ff; padding: 0.5em; color: black;\"> \n",
    "<b style=\"color: #2962ff;\">Question:</b> The following cell will plot the value of the coordinates of the solution for various values of $l_2$.\n",
    "    <ul>\n",
    "        <li> Interpret the plot and explain what can $L_2$ regularization be used for.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.visuals import l2_regularization_plot\n",
    "\n",
    "clf = lambda l2: LogisticRegression(solver='gd', l1=0.01, l2=l2, max_iter=1000)\n",
    "\n",
    "l2_regularization_plot(clf, A_train, b_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer:**\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"color: #ffffff; background-color: #2979ff; border-bottom: 5px solid #004ecb; padding: 2em;\"> \n",
    "<h1>V. Further development</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your time left, we would encourage you to consider going beyond these questions so that you develop certain aspects, depending on your personal interests and skills. For instance:\n",
    "- Implementations and numerical tests (further developments, more experiments, etc.)\n",
    "- Applications in learning or statistics (interpretation of some results, other models, other datasets, etc.)\n",
    "- Theoretical or mathematical questions (convergence proofs, convergence rates, advanced versions of an algorithm, theoretical analysis of special cases, etc.) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
